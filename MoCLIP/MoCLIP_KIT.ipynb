{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from transformers import CLIPModel, CLIPTokenizer\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np  \n",
    "\n",
    "seed = 42  \n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "from motion_loader import get_dataset_loader  \n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from argparse import Namespace\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "0.0001\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('config_KIT.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "opt = Namespace(**config)\n",
    "\n",
    "\n",
    "print(opt.batch_size)  \n",
    "print(opt.lr)          \n",
    "print(opt.device)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      " Loading gt_eval mode KIT dataset ...\n",
      "/home/user/dxc/motion/StableMoFusion/data/kit_std.npy\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/KIT-ML/Mean.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgt_eval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m get_dataset_loader(\n\u001b[1;32m      8\u001b[0m     opt,\n\u001b[1;32m      9\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     10\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_eval\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/motion/StableMoFusion/motion_loader/dataset_motion_loaders.py:10\u001b[0m, in \u001b[0;36mget_dataset_loader\u001b[0;34m(opt, batch_size, mode, split, accelerator)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataset_loader\u001b[39m(opt, batch_size, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m,split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading dataset...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_eval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     12\u001b[0m         dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     13\u001b[0m             dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m             num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     15\u001b[0m         ) \n",
      "File \u001b[0;32m~/motion/StableMoFusion/datasets/__init__.py:12\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(opt, split, mode, accelerator)\u001b[0m\n\u001b[1;32m     10\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m HumanML3D(opt, split, mode, accelerator)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mdataset_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkit\u001b[39m\u001b[38;5;124m'\u001b[39m :\n\u001b[0;32m---> 12\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mKIT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset Does Not Exist\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/motion/StableMoFusion/datasets/t2m_dataset_true.py:254\u001b[0m, in \u001b[0;36mKIT.__init__\u001b[0;34m(self, opt, split, mode, accelerator)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Loading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m mode KIT dataset ...\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m mode)\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/motion/StableMoFusion/datasets/t2m_dataset_true.py:37\u001b[0m, in \u001b[0;36mText2MotionDataset.__init__\u001b[0;34m(self, opt, split, mode, accelerator)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pjoin(opt\u001b[38;5;241m.\u001b[39meval_meta_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopt\u001b[38;5;241m.\u001b[39mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_std.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# used by T2M models (including evaluators)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# mean = np.load(pjoin(opt.eval_meta_dir, f'{opt.dataset_name}_mean.npy'))\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# std = np.load(pjoin(opt.eval_meta_dir, f'{opt.dataset_name}_std.npy'))\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# CMP\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMean.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(pjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStd.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/stablemofusion/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/KIT-ML/Mean.npy'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = get_dataset_loader(\n",
    "        opt,\n",
    "        batch_size=opt.batch_size,\n",
    "        split='train',\n",
    "        mode='gt_eval'\n",
    "    )\n",
    "test_loader = get_dataset_loader(\n",
    "    opt,\n",
    "    batch_size=opt.batch_size,\n",
    "    split='test',\n",
    "    mode='gt_eval'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load clip model for stage 1 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clip_model = CLIPModel.from_pretrained(opt.clip_model_name)\n",
    "clip_tokenizer = CLIPTokenizer.from_pretrained(opt.clip_model_name)\n",
    "\n",
    "\n",
    "for name, param in clip_model.named_parameters():\n",
    "    if \"text_model\" in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "motion_encoder = MotionEncoder(\n",
    "    input_dim=opt.input_dim,\n",
    "    embed_dim=opt.embed_dim,\n",
    "    num_heads=8,\n",
    "    num_layers=4,         \n",
    "    dim_feedforward=2048,\n",
    "    dropout=0.2,\n",
    "    max_seq_length=opt.max_seq_length\n",
    ")\n",
    "model = ClipMotionAlignModel(\n",
    "    clip_model=clip_model,\n",
    "    motion_encoder=motion_encoder,\n",
    "    temperature=0.07\n",
    ").to(opt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=opt.lr,\n",
    "        weight_decay=opt.weight_decay\n",
    "    )\n",
    "\n",
    "best_test_loss = float(\"inf\")\n",
    "no_improve_count = 0\n",
    "max_no_improve = 3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300: 100%|██████████| 30/30 [00:03<00:00,  7.75it/s, loss=2.5532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300] - Train Average Loss: 2.7950\n",
      "[Validate at epoch 1] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_1_Test: 100%|██████████| 22/22 [00:01<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_1_Test Average Contrastive Loss: 2.4003\n",
      "Epoch_1_Test M->T Retrieval (per 32 samples): R@1=0.216, R@2=0.384, R@3=0.503\n",
      "Epoch_1_Test T->M Retrieval (per 32 samples): R@1=0.224, R@2=0.402, R@3=0.528\n",
      "Model saved: clip_motion_align_epoch_KIT_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300: 100%|██████████| 30/30 [00:02<00:00, 11.04it/s, loss=1.9454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300] - Train Average Loss: 2.1803\n",
      "[Validate at epoch 2] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_2_Test: 100%|██████████| 22/22 [00:01<00:00, 21.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_2_Test Average Contrastive Loss: 2.1095\n",
      "Epoch_2_Test M->T Retrieval (per 32 samples): R@1=0.283, R@2=0.472, R@3=0.591\n",
      "Epoch_2_Test T->M Retrieval (per 32 samples): R@1=0.314, R@2=0.499, R@3=0.632\n",
      "Model saved: clip_motion_align_epoch_KIT_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300: 100%|██████████| 30/30 [00:02<00:00, 11.68it/s, loss=1.9369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300] - Train Average Loss: 1.8235\n",
      "[Validate at epoch 3] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_3_Test: 100%|██████████| 22/22 [00:00<00:00, 22.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_3_Test Average Contrastive Loss: 2.0060\n",
      "Epoch_3_Test M->T Retrieval (per 32 samples): R@1=0.301, R@2=0.483, R@3=0.591\n",
      "Epoch_3_Test T->M Retrieval (per 32 samples): R@1=0.335, R@2=0.540, R@3=0.686\n",
      "Model saved: clip_motion_align_epoch_KIT_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300: 100%|██████████| 30/30 [00:02<00:00, 11.20it/s, loss=1.5030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300] - Train Average Loss: 1.5885\n",
      "[Validate at epoch 4] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_4_Test: 100%|██████████| 22/22 [00:00<00:00, 22.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_4_Test Average Contrastive Loss: 1.7729\n",
      "Epoch_4_Test M->T Retrieval (per 32 samples): R@1=0.362, R@2=0.591, R@3=0.706\n",
      "Epoch_4_Test T->M Retrieval (per 32 samples): R@1=0.393, R@2=0.608, R@3=0.741\n",
      "Model saved: clip_motion_align_epoch_KIT_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300: 100%|██████████| 30/30 [00:02<00:00, 11.14it/s, loss=1.5383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300] - Train Average Loss: 1.3343\n",
      "[Validate at epoch 5] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_5_Test: 100%|██████████| 22/22 [00:00<00:00, 22.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_5_Test Average Contrastive Loss: 1.7477\n",
      "Epoch_5_Test M->T Retrieval (per 32 samples): R@1=0.385, R@2=0.604, R@3=0.713\n",
      "Epoch_5_Test T->M Retrieval (per 32 samples): R@1=0.409, R@2=0.621, R@3=0.740\n",
      "Model saved: clip_motion_align_epoch_KIT_5.pt\n",
      "Stage 2: Fine-tuning CLIP text encoder's last layer (and final_layer_norm) with lower lr.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300: 100%|██████████| 30/30 [00:02<00:00, 10.82it/s, loss=1.2861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300] - Train Average Loss: 1.1751\n",
      "[Validate at epoch 6] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_6_Test: 100%|██████████| 22/22 [00:00<00:00, 22.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_6_Test Average Contrastive Loss: 1.7107\n",
      "Epoch_6_Test M->T Retrieval (per 32 samples): R@1=0.381, R@2=0.591, R@3=0.726\n",
      "Epoch_6_Test T->M Retrieval (per 32 samples): R@1=0.409, R@2=0.612, R@3=0.749\n",
      "Model saved: clip_motion_align_epoch_KIT_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300: 100%|██████████| 30/30 [00:02<00:00, 10.60it/s, loss=0.9888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300] - Train Average Loss: 1.1113\n",
      "[Validate at epoch 7] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_7_Test: 100%|██████████| 22/22 [00:01<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_7_Test Average Contrastive Loss: 1.6461\n",
      "Epoch_7_Test M->T Retrieval (per 32 samples): R@1=0.425, R@2=0.636, R@3=0.751\n",
      "Epoch_7_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.655, R@3=0.767\n",
      "Model saved: clip_motion_align_epoch_KIT_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300: 100%|██████████| 30/30 [00:02<00:00, 10.67it/s, loss=0.8657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300] - Train Average Loss: 1.0205\n",
      "[Validate at epoch 8] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_8_Test: 100%|██████████| 22/22 [00:00<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_8_Test Average Contrastive Loss: 1.6461\n",
      "Epoch_8_Test M->T Retrieval (per 32 samples): R@1=0.391, R@2=0.614, R@3=0.746\n",
      "Epoch_8_Test T->M Retrieval (per 32 samples): R@1=0.445, R@2=0.659, R@3=0.776\n",
      "Model saved: clip_motion_align_epoch_KIT_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300: 100%|██████████| 30/30 [00:02<00:00, 10.74it/s, loss=0.7568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300] - Train Average Loss: 1.0636\n",
      "[Validate at epoch 9] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_9_Test: 100%|██████████| 22/22 [00:01<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_9_Test Average Contrastive Loss: 1.6372\n",
      "Epoch_9_Test M->T Retrieval (per 32 samples): R@1=0.405, R@2=0.619, R@3=0.751\n",
      "Epoch_9_Test T->M Retrieval (per 32 samples): R@1=0.419, R@2=0.624, R@3=0.754\n",
      "Model saved: clip_motion_align_epoch_KIT_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300: 100%|██████████| 30/30 [00:02<00:00, 10.44it/s, loss=0.7973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300] - Train Average Loss: 0.9406\n",
      "[Validate at epoch 10] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_10_Test: 100%|██████████| 22/22 [00:01<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_10_Test Average Contrastive Loss: 1.6563\n",
      "Epoch_10_Test M->T Retrieval (per 32 samples): R@1=0.406, R@2=0.635, R@3=0.761\n",
      "Epoch_10_Test T->M Retrieval (per 32 samples): R@1=0.402, R@2=0.653, R@3=0.771\n",
      "Model saved: clip_motion_align_epoch_KIT_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300: 100%|██████████| 30/30 [00:02<00:00, 10.71it/s, loss=0.7034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300] - Train Average Loss: 0.9351\n",
      "[Validate at epoch 11] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_11_Test: 100%|██████████| 22/22 [00:00<00:00, 22.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_11_Test Average Contrastive Loss: 1.6523\n",
      "Epoch_11_Test M->T Retrieval (per 32 samples): R@1=0.413, R@2=0.625, R@3=0.757\n",
      "Epoch_11_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.643, R@3=0.760\n",
      "Model saved: clip_motion_align_epoch_KIT_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300: 100%|██████████| 30/30 [00:02<00:00, 10.49it/s, loss=0.8813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300] - Train Average Loss: 0.9008\n",
      "[Validate at epoch 12] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_12_Test: 100%|██████████| 22/22 [00:01<00:00, 21.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_12_Test Average Contrastive Loss: 1.6173\n",
      "Epoch_12_Test M->T Retrieval (per 32 samples): R@1=0.420, R@2=0.635, R@3=0.751\n",
      "Epoch_12_Test T->M Retrieval (per 32 samples): R@1=0.445, R@2=0.655, R@3=0.774\n",
      "Model saved: clip_motion_align_epoch_KIT_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300: 100%|██████████| 30/30 [00:02<00:00, 10.70it/s, loss=0.6806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300] - Train Average Loss: 0.8440\n",
      "[Validate at epoch 13] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_13_Test: 100%|██████████| 22/22 [00:00<00:00, 22.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_13_Test Average Contrastive Loss: 1.6327\n",
      "Epoch_13_Test M->T Retrieval (per 32 samples): R@1=0.412, R@2=0.624, R@3=0.771\n",
      "Epoch_13_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.649, R@3=0.786\n",
      "Model saved: clip_motion_align_epoch_KIT_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300: 100%|██████████| 30/30 [00:02<00:00, 11.83it/s, loss=0.9139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300] - Train Average Loss: 0.8830\n",
      "[Validate at epoch 14] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_14_Test: 100%|██████████| 22/22 [00:00<00:00, 22.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_14_Test Average Contrastive Loss: 1.5854\n",
      "Epoch_14_Test M->T Retrieval (per 32 samples): R@1=0.428, R@2=0.663, R@3=0.780\n",
      "Epoch_14_Test T->M Retrieval (per 32 samples): R@1=0.466, R@2=0.662, R@3=0.788\n",
      "Model saved: clip_motion_align_epoch_KIT_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300: 100%|██████████| 30/30 [00:02<00:00, 10.56it/s, loss=1.1938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300] - Train Average Loss: 0.8690\n",
      "[Validate at epoch 15] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_15_Test: 100%|██████████| 22/22 [00:01<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_15_Test Average Contrastive Loss: 1.6273\n",
      "Epoch_15_Test M->T Retrieval (per 32 samples): R@1=0.443, R@2=0.669, R@3=0.767\n",
      "Epoch_15_Test T->M Retrieval (per 32 samples): R@1=0.406, R@2=0.646, R@3=0.767\n",
      "Model saved: clip_motion_align_epoch_KIT_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300: 100%|██████████| 30/30 [00:02<00:00, 11.08it/s, loss=1.0129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300] - Train Average Loss: 0.8606\n",
      "[Validate at epoch 16] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_16_Test: 100%|██████████| 22/22 [00:00<00:00, 25.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_16_Test Average Contrastive Loss: 1.5764\n",
      "Epoch_16_Test M->T Retrieval (per 32 samples): R@1=0.443, R@2=0.662, R@3=0.764\n",
      "Epoch_16_Test T->M Retrieval (per 32 samples): R@1=0.463, R@2=0.668, R@3=0.781\n",
      "Model saved: clip_motion_align_epoch_KIT_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300: 100%|██████████| 30/30 [00:02<00:00, 10.64it/s, loss=0.8548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300] - Train Average Loss: 0.8229\n",
      "[Validate at epoch 17] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_17_Test: 100%|██████████| 22/22 [00:00<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_17_Test Average Contrastive Loss: 1.6506\n",
      "Epoch_17_Test M->T Retrieval (per 32 samples): R@1=0.452, R@2=0.639, R@3=0.756\n",
      "Epoch_17_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.668, R@3=0.778\n",
      "Model saved: clip_motion_align_epoch_KIT_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300: 100%|██████████| 30/30 [00:02<00:00, 11.75it/s, loss=1.2670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300] - Train Average Loss: 0.8090\n",
      "[Validate at epoch 18] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_18_Test: 100%|██████████| 22/22 [00:00<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_18_Test Average Contrastive Loss: 1.6195\n",
      "Epoch_18_Test M->T Retrieval (per 32 samples): R@1=0.425, R@2=0.632, R@3=0.763\n",
      "Epoch_18_Test T->M Retrieval (per 32 samples): R@1=0.463, R@2=0.655, R@3=0.764\n",
      "Model saved: clip_motion_align_epoch_KIT_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300: 100%|██████████| 30/30 [00:02<00:00, 10.91it/s, loss=0.6178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300] - Train Average Loss: 0.7818\n",
      "[Validate at epoch 19] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_19_Test: 100%|██████████| 22/22 [00:00<00:00, 22.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_19_Test Average Contrastive Loss: 1.6379\n",
      "Epoch_19_Test M->T Retrieval (per 32 samples): R@1=0.419, R@2=0.648, R@3=0.773\n",
      "Epoch_19_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.619, R@3=0.753\n",
      "Model saved: clip_motion_align_epoch_KIT_19.pt\n",
      "Early stopping triggered!\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.num_epochs):\n",
    "    \n",
    "    if epoch + 1 == opt.pretrain_epochs + 1:\n",
    "        \n",
    "        for param in clip_model.text_model.encoder.layers[-1].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in clip_model.text_model.final_layer_norm.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=opt.lr_finetune,\n",
    "            weight_decay=opt.weight_decay\n",
    "        )\n",
    "        print(\"Stage 2: Fine-tuning CLIP text encoder's last layer (and final_layer_norm) with lower lr.\")\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{opt.num_epochs}\")\n",
    "\n",
    "\n",
    "\n",
    "    for step, batch_data in enumerate(pbar):\n",
    "        caption, motion, m_length = batch_data\n",
    "\n",
    "        \n",
    "        caption = [c.lower() for c in caption]\n",
    "        text_enc = clip_tokenizer(\n",
    "            caption,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=opt.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = text_enc[\"input_ids\"].to(opt.device)\n",
    "        attention_mask = text_enc[\"attention_mask\"].to(opt.device)\n",
    "\n",
    "       \n",
    "        if isinstance(motion, list):\n",
    "            motion = torch.stack([torch.tensor(m, dtype=torch.float32) for m in motion], dim=0)\n",
    "        else:\n",
    "            motion = motion.float()\n",
    "        motion = motion.to(opt.device)\n",
    "        m_length = m_length.to(opt.device)\n",
    "\n",
    "        \n",
    "        motion_emb, text_emb = model(motion, m_length, input_ids, attention_mask)\n",
    "        loss = clip_contrastive_loss(motion_emb, text_emb, model.logit_scale)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_loss = total_loss / max(count, 1)\n",
    "    print(f\"Epoch [{epoch+1}/{opt.num_epochs}] - Train Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "   \n",
    "    print(f\"[Validate at epoch {epoch+1}] ...\")\n",
    "    test_loss = evaluate_model(model, test_loader, clip_tokenizer, opt, desc=f\"Epoch_{epoch+1}_Test\")\n",
    "    model_path = f\"clip_motion_align_epoch_KIT_{epoch+1}.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved: {model_path}\")\n",
    "\n",
    "   \n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        no_improve_count = 0\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "        if no_improve_count >= max_no_improve:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stablemofusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
