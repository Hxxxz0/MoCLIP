{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from transformers import CLIPModel, CLIPTokenizer\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np  \n",
    "\n",
    "seed = 42  \n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "sys.path.append(os.path.abspath('/home/user/dxc/motion/StableMoFusion/'))\n",
    "from motion_loader import get_dataset_loader  \n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from argparse import Namespace\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "0.0001\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('config_KIT.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "opt = Namespace(**config)\n",
    "\n",
    "\n",
    "print(opt.batch_size)  \n",
    "print(opt.lr)          \n",
    "print(opt.device)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading train mode KIT dataset ...\n",
      "11111111111111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24621e3574ea4527b4529490f931d421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing loading kit dataset\n",
      "\n",
      " Loading gt_eval mode KIT dataset ...\n",
      "11111111111111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdc2448e6454d12a263c7d0d33b5223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing loading kit dataset\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath('/home/user/dxc/motion/StableMoFusion'))\n",
    "train_loader = get_dataset_loader(\n",
    "        opt,\n",
    "        batch_size=opt.batch_size,\n",
    "        split='train',\n",
    "        mode='train'\n",
    "    )\n",
    "test_loader = get_dataset_loader(\n",
    "    opt,\n",
    "    batch_size=opt.batch_size,\n",
    "    split='test',\n",
    "    mode='gt_eval'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load clip model for stage 1 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clip_model = CLIPModel.from_pretrained(opt.clip_model_name)\n",
    "clip_tokenizer = CLIPTokenizer.from_pretrained(opt.clip_model_name)\n",
    "\n",
    "# 初始阶段：冻结整个 CLIP 文本编码器（stage 1）\n",
    "for name, param in clip_model.named_parameters():\n",
    "    if \"text_model\" in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "motion_encoder = MotionEncoder(\n",
    "    input_dim=opt.input_dim,\n",
    "    embed_dim=opt.embed_dim,\n",
    "    num_heads=8,\n",
    "    num_layers=4,         \n",
    "    dim_feedforward=2048,\n",
    "    dropout=0.2,\n",
    "    max_seq_length=opt.max_seq_length\n",
    ")\n",
    "model = ClipMotionAlignModel(\n",
    "    clip_model=clip_model,\n",
    "    motion_encoder=motion_encoder,\n",
    "    temperature=0.07\n",
    ").to(opt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=opt.lr,\n",
    "        weight_decay=opt.weight_decay\n",
    "    )\n",
    "\n",
    "best_test_loss = float(\"inf\")\n",
    "no_improve_count = 0\n",
    "max_no_improve = 3  # 连续3次验证无改进则早停"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300: 100%|██████████| 30/30 [00:03<00:00,  7.75it/s, loss=2.5532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300] - Train Average Loss: 2.7950\n",
      "[Validate at epoch 1] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_1_Test: 100%|██████████| 22/22 [00:01<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_1_Test Average Contrastive Loss: 2.4003\n",
      "Epoch_1_Test M->T Retrieval (per 32 samples): R@1=0.216, R@2=0.384, R@3=0.503\n",
      "Epoch_1_Test T->M Retrieval (per 32 samples): R@1=0.224, R@2=0.402, R@3=0.528\n",
      "Model saved: clip_motion_align_epoch_KIT_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300: 100%|██████████| 30/30 [00:02<00:00, 11.04it/s, loss=1.9454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300] - Train Average Loss: 2.1803\n",
      "[Validate at epoch 2] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_2_Test: 100%|██████████| 22/22 [00:01<00:00, 21.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_2_Test Average Contrastive Loss: 2.1095\n",
      "Epoch_2_Test M->T Retrieval (per 32 samples): R@1=0.283, R@2=0.472, R@3=0.591\n",
      "Epoch_2_Test T->M Retrieval (per 32 samples): R@1=0.314, R@2=0.499, R@3=0.632\n",
      "Model saved: clip_motion_align_epoch_KIT_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300: 100%|██████████| 30/30 [00:02<00:00, 11.68it/s, loss=1.9369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300] - Train Average Loss: 1.8235\n",
      "[Validate at epoch 3] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_3_Test: 100%|██████████| 22/22 [00:00<00:00, 22.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_3_Test Average Contrastive Loss: 2.0060\n",
      "Epoch_3_Test M->T Retrieval (per 32 samples): R@1=0.301, R@2=0.483, R@3=0.591\n",
      "Epoch_3_Test T->M Retrieval (per 32 samples): R@1=0.335, R@2=0.540, R@3=0.686\n",
      "Model saved: clip_motion_align_epoch_KIT_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300: 100%|██████████| 30/30 [00:02<00:00, 11.20it/s, loss=1.5030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300] - Train Average Loss: 1.5885\n",
      "[Validate at epoch 4] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_4_Test: 100%|██████████| 22/22 [00:00<00:00, 22.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_4_Test Average Contrastive Loss: 1.7729\n",
      "Epoch_4_Test M->T Retrieval (per 32 samples): R@1=0.362, R@2=0.591, R@3=0.706\n",
      "Epoch_4_Test T->M Retrieval (per 32 samples): R@1=0.393, R@2=0.608, R@3=0.741\n",
      "Model saved: clip_motion_align_epoch_KIT_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300: 100%|██████████| 30/30 [00:02<00:00, 11.14it/s, loss=1.5383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300] - Train Average Loss: 1.3343\n",
      "[Validate at epoch 5] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_5_Test: 100%|██████████| 22/22 [00:00<00:00, 22.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_5_Test Average Contrastive Loss: 1.7477\n",
      "Epoch_5_Test M->T Retrieval (per 32 samples): R@1=0.385, R@2=0.604, R@3=0.713\n",
      "Epoch_5_Test T->M Retrieval (per 32 samples): R@1=0.409, R@2=0.621, R@3=0.740\n",
      "Model saved: clip_motion_align_epoch_KIT_5.pt\n",
      "Stage 2: Fine-tuning CLIP text encoder's last layer (and final_layer_norm) with lower lr.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300: 100%|██████████| 30/30 [00:02<00:00, 10.82it/s, loss=1.2861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300] - Train Average Loss: 1.1751\n",
      "[Validate at epoch 6] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_6_Test: 100%|██████████| 22/22 [00:00<00:00, 22.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_6_Test Average Contrastive Loss: 1.7107\n",
      "Epoch_6_Test M->T Retrieval (per 32 samples): R@1=0.381, R@2=0.591, R@3=0.726\n",
      "Epoch_6_Test T->M Retrieval (per 32 samples): R@1=0.409, R@2=0.612, R@3=0.749\n",
      "Model saved: clip_motion_align_epoch_KIT_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300: 100%|██████████| 30/30 [00:02<00:00, 10.60it/s, loss=0.9888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300] - Train Average Loss: 1.1113\n",
      "[Validate at epoch 7] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_7_Test: 100%|██████████| 22/22 [00:01<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_7_Test Average Contrastive Loss: 1.6461\n",
      "Epoch_7_Test M->T Retrieval (per 32 samples): R@1=0.425, R@2=0.636, R@3=0.751\n",
      "Epoch_7_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.655, R@3=0.767\n",
      "Model saved: clip_motion_align_epoch_KIT_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300: 100%|██████████| 30/30 [00:02<00:00, 10.67it/s, loss=0.8657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300] - Train Average Loss: 1.0205\n",
      "[Validate at epoch 8] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_8_Test: 100%|██████████| 22/22 [00:00<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_8_Test Average Contrastive Loss: 1.6461\n",
      "Epoch_8_Test M->T Retrieval (per 32 samples): R@1=0.391, R@2=0.614, R@3=0.746\n",
      "Epoch_8_Test T->M Retrieval (per 32 samples): R@1=0.445, R@2=0.659, R@3=0.776\n",
      "Model saved: clip_motion_align_epoch_KIT_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300: 100%|██████████| 30/30 [00:02<00:00, 10.74it/s, loss=0.7568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300] - Train Average Loss: 1.0636\n",
      "[Validate at epoch 9] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_9_Test: 100%|██████████| 22/22 [00:01<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_9_Test Average Contrastive Loss: 1.6372\n",
      "Epoch_9_Test M->T Retrieval (per 32 samples): R@1=0.405, R@2=0.619, R@3=0.751\n",
      "Epoch_9_Test T->M Retrieval (per 32 samples): R@1=0.419, R@2=0.624, R@3=0.754\n",
      "Model saved: clip_motion_align_epoch_KIT_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300: 100%|██████████| 30/30 [00:02<00:00, 10.44it/s, loss=0.7973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300] - Train Average Loss: 0.9406\n",
      "[Validate at epoch 10] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_10_Test: 100%|██████████| 22/22 [00:01<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_10_Test Average Contrastive Loss: 1.6563\n",
      "Epoch_10_Test M->T Retrieval (per 32 samples): R@1=0.406, R@2=0.635, R@3=0.761\n",
      "Epoch_10_Test T->M Retrieval (per 32 samples): R@1=0.402, R@2=0.653, R@3=0.771\n",
      "Model saved: clip_motion_align_epoch_KIT_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300: 100%|██████████| 30/30 [00:02<00:00, 10.71it/s, loss=0.7034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300] - Train Average Loss: 0.9351\n",
      "[Validate at epoch 11] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_11_Test: 100%|██████████| 22/22 [00:00<00:00, 22.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_11_Test Average Contrastive Loss: 1.6523\n",
      "Epoch_11_Test M->T Retrieval (per 32 samples): R@1=0.413, R@2=0.625, R@3=0.757\n",
      "Epoch_11_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.643, R@3=0.760\n",
      "Model saved: clip_motion_align_epoch_KIT_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300: 100%|██████████| 30/30 [00:02<00:00, 10.49it/s, loss=0.8813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300] - Train Average Loss: 0.9008\n",
      "[Validate at epoch 12] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_12_Test: 100%|██████████| 22/22 [00:01<00:00, 21.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_12_Test Average Contrastive Loss: 1.6173\n",
      "Epoch_12_Test M->T Retrieval (per 32 samples): R@1=0.420, R@2=0.635, R@3=0.751\n",
      "Epoch_12_Test T->M Retrieval (per 32 samples): R@1=0.445, R@2=0.655, R@3=0.774\n",
      "Model saved: clip_motion_align_epoch_KIT_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300: 100%|██████████| 30/30 [00:02<00:00, 10.70it/s, loss=0.6806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300] - Train Average Loss: 0.8440\n",
      "[Validate at epoch 13] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_13_Test: 100%|██████████| 22/22 [00:00<00:00, 22.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_13_Test Average Contrastive Loss: 1.6327\n",
      "Epoch_13_Test M->T Retrieval (per 32 samples): R@1=0.412, R@2=0.624, R@3=0.771\n",
      "Epoch_13_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.649, R@3=0.786\n",
      "Model saved: clip_motion_align_epoch_KIT_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300: 100%|██████████| 30/30 [00:02<00:00, 11.83it/s, loss=0.9139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300] - Train Average Loss: 0.8830\n",
      "[Validate at epoch 14] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_14_Test: 100%|██████████| 22/22 [00:00<00:00, 22.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_14_Test Average Contrastive Loss: 1.5854\n",
      "Epoch_14_Test M->T Retrieval (per 32 samples): R@1=0.428, R@2=0.663, R@3=0.780\n",
      "Epoch_14_Test T->M Retrieval (per 32 samples): R@1=0.466, R@2=0.662, R@3=0.788\n",
      "Model saved: clip_motion_align_epoch_KIT_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300: 100%|██████████| 30/30 [00:02<00:00, 10.56it/s, loss=1.1938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300] - Train Average Loss: 0.8690\n",
      "[Validate at epoch 15] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_15_Test: 100%|██████████| 22/22 [00:01<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_15_Test Average Contrastive Loss: 1.6273\n",
      "Epoch_15_Test M->T Retrieval (per 32 samples): R@1=0.443, R@2=0.669, R@3=0.767\n",
      "Epoch_15_Test T->M Retrieval (per 32 samples): R@1=0.406, R@2=0.646, R@3=0.767\n",
      "Model saved: clip_motion_align_epoch_KIT_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300: 100%|██████████| 30/30 [00:02<00:00, 11.08it/s, loss=1.0129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300] - Train Average Loss: 0.8606\n",
      "[Validate at epoch 16] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_16_Test: 100%|██████████| 22/22 [00:00<00:00, 25.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_16_Test Average Contrastive Loss: 1.5764\n",
      "Epoch_16_Test M->T Retrieval (per 32 samples): R@1=0.443, R@2=0.662, R@3=0.764\n",
      "Epoch_16_Test T->M Retrieval (per 32 samples): R@1=0.463, R@2=0.668, R@3=0.781\n",
      "Model saved: clip_motion_align_epoch_KIT_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300: 100%|██████████| 30/30 [00:02<00:00, 10.64it/s, loss=0.8548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300] - Train Average Loss: 0.8229\n",
      "[Validate at epoch 17] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_17_Test: 100%|██████████| 22/22 [00:00<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_17_Test Average Contrastive Loss: 1.6506\n",
      "Epoch_17_Test M->T Retrieval (per 32 samples): R@1=0.452, R@2=0.639, R@3=0.756\n",
      "Epoch_17_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.668, R@3=0.778\n",
      "Model saved: clip_motion_align_epoch_KIT_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300: 100%|██████████| 30/30 [00:02<00:00, 11.75it/s, loss=1.2670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300] - Train Average Loss: 0.8090\n",
      "[Validate at epoch 18] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_18_Test: 100%|██████████| 22/22 [00:00<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_18_Test Average Contrastive Loss: 1.6195\n",
      "Epoch_18_Test M->T Retrieval (per 32 samples): R@1=0.425, R@2=0.632, R@3=0.763\n",
      "Epoch_18_Test T->M Retrieval (per 32 samples): R@1=0.463, R@2=0.655, R@3=0.764\n",
      "Model saved: clip_motion_align_epoch_KIT_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300: 100%|██████████| 30/30 [00:02<00:00, 10.91it/s, loss=0.6178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300] - Train Average Loss: 0.7818\n",
      "[Validate at epoch 19] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_19_Test: 100%|██████████| 22/22 [00:00<00:00, 22.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_19_Test Average Contrastive Loss: 1.6379\n",
      "Epoch_19_Test M->T Retrieval (per 32 samples): R@1=0.419, R@2=0.648, R@3=0.773\n",
      "Epoch_19_Test T->M Retrieval (per 32 samples): R@1=0.433, R@2=0.619, R@3=0.753\n",
      "Model saved: clip_motion_align_epoch_KIT_19.pt\n",
      "Early stopping triggered!\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.num_epochs):\n",
    "    \n",
    "    if epoch + 1 == opt.pretrain_epochs + 1:\n",
    "        \n",
    "        for param in clip_model.text_model.encoder.layers[-1].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in clip_model.text_model.final_layer_norm.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=opt.lr_finetune,\n",
    "            weight_decay=opt.weight_decay\n",
    "        )\n",
    "        print(\"Stage 2: Fine-tuning CLIP text encoder's last layer (and final_layer_norm) with lower lr.\")\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{opt.num_epochs}\")\n",
    "\n",
    "\n",
    "\n",
    "    for step, batch_data in enumerate(pbar):\n",
    "        caption, motion, m_length = batch_data\n",
    "\n",
    "        \n",
    "        caption = [c.lower() for c in caption]\n",
    "        text_enc = clip_tokenizer(\n",
    "            caption,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=opt.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = text_enc[\"input_ids\"].to(opt.device)\n",
    "        attention_mask = text_enc[\"attention_mask\"].to(opt.device)\n",
    "\n",
    "       \n",
    "        if isinstance(motion, list):\n",
    "            motion = torch.stack([torch.tensor(m, dtype=torch.float32) for m in motion], dim=0)\n",
    "        else:\n",
    "            motion = motion.float()\n",
    "        motion = motion.to(opt.device)\n",
    "        m_length = m_length.to(opt.device)\n",
    "\n",
    "        \n",
    "        motion_emb, text_emb = model(motion, m_length, input_ids, attention_mask)\n",
    "        loss = clip_contrastive_loss(motion_emb, text_emb, model.logit_scale)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_loss = total_loss / max(count, 1)\n",
    "    print(f\"Epoch [{epoch+1}/{opt.num_epochs}] - Train Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "   \n",
    "    print(f\"[Validate at epoch {epoch+1}] ...\")\n",
    "    test_loss = evaluate_model(model, test_loader, clip_tokenizer, opt, desc=f\"Epoch_{epoch+1}_Test\")\n",
    "    model_path = f\"clip_motion_align_epoch_KIT_{epoch+1}.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved: {model_path}\")\n",
    "\n",
    "   \n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        no_improve_count = 0\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "        if no_improve_count >= max_no_improve:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stablemofusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
