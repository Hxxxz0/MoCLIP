{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from transformers import CLIPModel, CLIPTokenizer\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np  \n",
    "\n",
    "seed = 42  \n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "sys.path.append(os.path.abspath('/home/user/dxc/motion/CLIP/'))\n",
    "from motion_loader import get_dataset_loader  \n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from argparse import Namespace\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "0.0001\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "opt = Namespace(**config)\n",
    "\n",
    "\n",
    "print(opt.batch_size)  \n",
    "print(opt.lr)          \n",
    "print(opt.device)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading CMP mode HumanML3D dataset ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9020e40dede47abbfbdee411c22dc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing loading t2m dataset\n",
      "\n",
      " Loading CMP mode HumanML3D dataset ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81065f8585ff457e87d6384692e9a286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing loading t2m dataset\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath('/home/user/dxc/motion/StableMoFusion'))\n",
    "train_loader = get_dataset_loader(\n",
    "        opt,\n",
    "        batch_size=opt.batch_size,\n",
    "        split='train',\n",
    "        mode='CMP'\n",
    "    )\n",
    "test_loader = get_dataset_loader(\n",
    "    opt,\n",
    "    batch_size=opt.batch_size,\n",
    "    split='test',\n",
    "    mode='CMP'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load clip model for stage 1 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clip_model = CLIPModel.from_pretrained(opt.clip_model_name)\n",
    "clip_tokenizer = CLIPTokenizer.from_pretrained(opt.clip_model_name)\n",
    "\n",
    "# 初始阶段：冻结整个 CLIP 文本编码器（stage 1）\n",
    "for name, param in clip_model.named_parameters():\n",
    "    if \"text_model\" in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "motion_encoder = MotionEncoder(\n",
    "    input_dim=opt.input_dim,\n",
    "    embed_dim=opt.embed_dim,\n",
    "    num_heads=8,\n",
    "    num_layers=4,         \n",
    "    dim_feedforward=2048,\n",
    "    dropout=0.2,\n",
    "    max_seq_length=opt.max_seq_length\n",
    ")\n",
    "model = ClipMotionAlignModel(\n",
    "    clip_model=clip_model,\n",
    "    motion_encoder=motion_encoder,\n",
    "    temperature=0.07\n",
    ").to(opt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=opt.lr,\n",
    "        weight_decay=opt.weight_decay\n",
    "    )\n",
    "\n",
    "best_test_loss = float(\"inf\")\n",
    "no_improve_count = 0\n",
    "max_no_improve = 3  # 连续3次验证无改进则早停"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300: 100%|██████████| 177/177 [00:18<00:00,  9.46it/s, loss=2.2014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300] - Train Average Loss: 2.7224\n",
      "[Validate at epoch 1] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_1_Test: 100%|██████████| 32/32 [00:02<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_1_Test Average Contrastive Loss: 2.2290\n",
      "Epoch_1_Test M->T Retrieval (per 32 samples): R@1=0.295, R@2=0.474, R@3=0.592\n",
      "Epoch_1_Test T->M Retrieval (per 32 samples): R@1=0.354, R@2=0.507, R@3=0.600\n",
      "Model saved: clip_motion_align_epoch_CMP_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300: 100%|██████████| 177/177 [00:18<00:00,  9.81it/s, loss=1.6996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300] - Train Average Loss: 1.9050\n",
      "[Validate at epoch 2] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_2_Test: 100%|██████████| 32/32 [00:02<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_2_Test Average Contrastive Loss: 1.8109\n",
      "Epoch_2_Test M->T Retrieval (per 32 samples): R@1=0.403, R@2=0.605, R@3=0.705\n",
      "Epoch_2_Test T->M Retrieval (per 32 samples): R@1=0.424, R@2=0.624, R@3=0.721\n",
      "Model saved: clip_motion_align_epoch_CMP_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300: 100%|██████████| 177/177 [00:17<00:00,  9.84it/s, loss=1.5163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/300] - Train Average Loss: 1.4865\n",
      "[Validate at epoch 3] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_3_Test: 100%|██████████| 32/32 [00:02<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_3_Test Average Contrastive Loss: 1.4372\n",
      "Epoch_3_Test M->T Retrieval (per 32 samples): R@1=0.541, R@2=0.732, R@3=0.805\n",
      "Epoch_3_Test T->M Retrieval (per 32 samples): R@1=0.549, R@2=0.733, R@3=0.835\n",
      "Model saved: clip_motion_align_epoch_CMP_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300: 100%|██████████| 177/177 [00:18<00:00,  9.56it/s, loss=1.3489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/300] - Train Average Loss: 1.2181\n",
      "[Validate at epoch 4] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_4_Test: 100%|██████████| 32/32 [00:02<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_4_Test Average Contrastive Loss: 1.3728\n",
      "Epoch_4_Test M->T Retrieval (per 32 samples): R@1=0.560, R@2=0.749, R@3=0.830\n",
      "Epoch_4_Test T->M Retrieval (per 32 samples): R@1=0.574, R@2=0.752, R@3=0.845\n",
      "Model saved: clip_motion_align_epoch_CMP_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/300: 100%|██████████| 177/177 [00:18<00:00,  9.53it/s, loss=1.0210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/300] - Train Average Loss: 1.0197\n",
      "[Validate at epoch 5] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_5_Test: 100%|██████████| 32/32 [00:02<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_5_Test Average Contrastive Loss: 1.2117\n",
      "Epoch_5_Test M->T Retrieval (per 32 samples): R@1=0.608, R@2=0.782, R@3=0.856\n",
      "Epoch_5_Test T->M Retrieval (per 32 samples): R@1=0.626, R@2=0.790, R@3=0.858\n",
      "Model saved: clip_motion_align_epoch_CMP_5.pt\n",
      "Stage 2: Fine-tuning CLIP text encoder's last layer (and final_layer_norm) with lower lr.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/300: 100%|██████████| 177/177 [00:19<00:00,  9.11it/s, loss=0.8055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/300] - Train Average Loss: 0.7359\n",
      "[Validate at epoch 6] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_6_Test: 100%|██████████| 32/32 [00:02<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_6_Test Average Contrastive Loss: 1.0161\n",
      "Epoch_6_Test M->T Retrieval (per 32 samples): R@1=0.664, R@2=0.821, R@3=0.896\n",
      "Epoch_6_Test T->M Retrieval (per 32 samples): R@1=0.665, R@2=0.842, R@3=0.901\n",
      "Model saved: clip_motion_align_epoch_CMP_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/300: 100%|██████████| 177/177 [00:19<00:00,  9.11it/s, loss=0.6336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/300] - Train Average Loss: 0.6391\n",
      "[Validate at epoch 7] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_7_Test: 100%|██████████| 32/32 [00:02<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_7_Test Average Contrastive Loss: 1.0283\n",
      "Epoch_7_Test M->T Retrieval (per 32 samples): R@1=0.656, R@2=0.830, R@3=0.901\n",
      "Epoch_7_Test T->M Retrieval (per 32 samples): R@1=0.669, R@2=0.849, R@3=0.903\n",
      "Model saved: clip_motion_align_epoch_CMP_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/300: 100%|██████████| 177/177 [00:19<00:00,  9.16it/s, loss=0.5799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/300] - Train Average Loss: 0.6104\n",
      "[Validate at epoch 8] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_8_Test: 100%|██████████| 32/32 [00:02<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_8_Test Average Contrastive Loss: 0.9902\n",
      "Epoch_8_Test M->T Retrieval (per 32 samples): R@1=0.673, R@2=0.831, R@3=0.897\n",
      "Epoch_8_Test T->M Retrieval (per 32 samples): R@1=0.668, R@2=0.830, R@3=0.902\n",
      "Model saved: clip_motion_align_epoch_CMP_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/300: 100%|██████████| 177/177 [00:19<00:00,  9.02it/s, loss=0.5914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/300] - Train Average Loss: 0.5607\n",
      "[Validate at epoch 9] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_9_Test: 100%|██████████| 32/32 [00:02<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_9_Test Average Contrastive Loss: 0.9535\n",
      "Epoch_9_Test M->T Retrieval (per 32 samples): R@1=0.689, R@2=0.843, R@3=0.908\n",
      "Epoch_9_Test T->M Retrieval (per 32 samples): R@1=0.685, R@2=0.853, R@3=0.914\n",
      "Model saved: clip_motion_align_epoch_CMP_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/300: 100%|██████████| 177/177 [00:19<00:00,  9.13it/s, loss=0.5823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300] - Train Average Loss: 0.5178\n",
      "[Validate at epoch 10] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_10_Test: 100%|██████████| 32/32 [00:02<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_10_Test Average Contrastive Loss: 0.9004\n",
      "Epoch_10_Test M->T Retrieval (per 32 samples): R@1=0.703, R@2=0.851, R@3=0.904\n",
      "Epoch_10_Test T->M Retrieval (per 32 samples): R@1=0.713, R@2=0.857, R@3=0.920\n",
      "Model saved: clip_motion_align_epoch_CMP_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/300: 100%|██████████| 177/177 [00:19<00:00,  9.07it/s, loss=0.4455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/300] - Train Average Loss: 0.4967\n",
      "[Validate at epoch 11] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_11_Test: 100%|██████████| 32/32 [00:02<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_11_Test Average Contrastive Loss: 0.8948\n",
      "Epoch_11_Test M->T Retrieval (per 32 samples): R@1=0.703, R@2=0.861, R@3=0.906\n",
      "Epoch_11_Test T->M Retrieval (per 32 samples): R@1=0.707, R@2=0.866, R@3=0.926\n",
      "Model saved: clip_motion_align_epoch_CMP_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/300: 100%|██████████| 177/177 [00:19<00:00,  9.15it/s, loss=0.3894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/300] - Train Average Loss: 0.4691\n",
      "[Validate at epoch 12] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_12_Test: 100%|██████████| 32/32 [00:02<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_12_Test Average Contrastive Loss: 0.8508\n",
      "Epoch_12_Test M->T Retrieval (per 32 samples): R@1=0.713, R@2=0.866, R@3=0.918\n",
      "Epoch_12_Test T->M Retrieval (per 32 samples): R@1=0.714, R@2=0.871, R@3=0.926\n",
      "Model saved: clip_motion_align_epoch_CMP_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/300: 100%|██████████| 177/177 [00:19<00:00,  9.16it/s, loss=0.6457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/300] - Train Average Loss: 0.4353\n",
      "[Validate at epoch 13] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_13_Test: 100%|██████████| 32/32 [00:02<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_13_Test Average Contrastive Loss: 0.8605\n",
      "Epoch_13_Test M->T Retrieval (per 32 samples): R@1=0.724, R@2=0.874, R@3=0.921\n",
      "Epoch_13_Test T->M Retrieval (per 32 samples): R@1=0.736, R@2=0.873, R@3=0.917\n",
      "Model saved: clip_motion_align_epoch_CMP_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/300: 100%|██████████| 177/177 [00:19<00:00,  9.16it/s, loss=0.4258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300] - Train Average Loss: 0.4168\n",
      "[Validate at epoch 14] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_14_Test: 100%|██████████| 32/32 [00:01<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_14_Test Average Contrastive Loss: 0.8106\n",
      "Epoch_14_Test M->T Retrieval (per 32 samples): R@1=0.730, R@2=0.876, R@3=0.928\n",
      "Epoch_14_Test T->M Retrieval (per 32 samples): R@1=0.723, R@2=0.871, R@3=0.931\n",
      "Model saved: clip_motion_align_epoch_CMP_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/300: 100%|██████████| 177/177 [00:19<00:00,  9.29it/s, loss=0.3557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/300] - Train Average Loss: 0.4022\n",
      "[Validate at epoch 15] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_15_Test: 100%|██████████| 32/32 [00:02<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_15_Test Average Contrastive Loss: 0.8424\n",
      "Epoch_15_Test M->T Retrieval (per 32 samples): R@1=0.724, R@2=0.867, R@3=0.922\n",
      "Epoch_15_Test T->M Retrieval (per 32 samples): R@1=0.726, R@2=0.866, R@3=0.929\n",
      "Model saved: clip_motion_align_epoch_CMP_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/300: 100%|██████████| 177/177 [00:19<00:00,  9.13it/s, loss=0.2716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/300] - Train Average Loss: 0.3798\n",
      "[Validate at epoch 16] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_16_Test: 100%|██████████| 32/32 [00:02<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_16_Test Average Contrastive Loss: 0.7899\n",
      "Epoch_16_Test M->T Retrieval (per 32 samples): R@1=0.726, R@2=0.882, R@3=0.930\n",
      "Epoch_16_Test T->M Retrieval (per 32 samples): R@1=0.754, R@2=0.883, R@3=0.930\n",
      "Model saved: clip_motion_align_epoch_CMP_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/300: 100%|██████████| 177/177 [00:19<00:00,  9.18it/s, loss=0.2762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/300] - Train Average Loss: 0.3740\n",
      "[Validate at epoch 17] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_17_Test: 100%|██████████| 32/32 [00:02<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_17_Test Average Contrastive Loss: 0.8065\n",
      "Epoch_17_Test M->T Retrieval (per 32 samples): R@1=0.740, R@2=0.884, R@3=0.926\n",
      "Epoch_17_Test T->M Retrieval (per 32 samples): R@1=0.745, R@2=0.876, R@3=0.926\n",
      "Model saved: clip_motion_align_epoch_CMP_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/300: 100%|██████████| 177/177 [00:19<00:00,  9.14it/s, loss=0.4987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/300] - Train Average Loss: 0.3485\n",
      "[Validate at epoch 18] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_18_Test: 100%|██████████| 32/32 [00:02<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_18_Test Average Contrastive Loss: 0.7774\n",
      "Epoch_18_Test M->T Retrieval (per 32 samples): R@1=0.747, R@2=0.885, R@3=0.926\n",
      "Epoch_18_Test T->M Retrieval (per 32 samples): R@1=0.747, R@2=0.885, R@3=0.932\n",
      "Model saved: clip_motion_align_epoch_CMP_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/300: 100%|██████████| 177/177 [00:19<00:00,  9.15it/s, loss=0.3709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/300] - Train Average Loss: 0.3459\n",
      "[Validate at epoch 19] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_19_Test: 100%|██████████| 32/32 [00:02<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_19_Test Average Contrastive Loss: 0.7510\n",
      "Epoch_19_Test M->T Retrieval (per 32 samples): R@1=0.750, R@2=0.889, R@3=0.936\n",
      "Epoch_19_Test T->M Retrieval (per 32 samples): R@1=0.759, R@2=0.898, R@3=0.938\n",
      "Model saved: clip_motion_align_epoch_CMP_19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/300: 100%|██████████| 177/177 [00:19<00:00,  9.17it/s, loss=0.3626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300] - Train Average Loss: 0.3309\n",
      "[Validate at epoch 20] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_20_Test: 100%|██████████| 32/32 [00:02<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_20_Test Average Contrastive Loss: 0.7458\n",
      "Epoch_20_Test M->T Retrieval (per 32 samples): R@1=0.739, R@2=0.888, R@3=0.936\n",
      "Epoch_20_Test T->M Retrieval (per 32 samples): R@1=0.740, R@2=0.892, R@3=0.938\n",
      "Model saved: clip_motion_align_epoch_CMP_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/300: 100%|██████████| 177/177 [00:19<00:00,  9.17it/s, loss=0.2003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300] - Train Average Loss: 0.3204\n",
      "[Validate at epoch 21] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_21_Test: 100%|██████████| 32/32 [00:01<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_21_Test Average Contrastive Loss: 0.7669\n",
      "Epoch_21_Test M->T Retrieval (per 32 samples): R@1=0.747, R@2=0.879, R@3=0.940\n",
      "Epoch_21_Test T->M Retrieval (per 32 samples): R@1=0.740, R@2=0.875, R@3=0.933\n",
      "Model saved: clip_motion_align_epoch_CMP_21.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/300: 100%|██████████| 177/177 [00:19<00:00,  9.24it/s, loss=0.2798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/300] - Train Average Loss: 0.3007\n",
      "[Validate at epoch 22] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_22_Test: 100%|██████████| 32/32 [00:02<00:00, 15.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_22_Test Average Contrastive Loss: 0.7133\n",
      "Epoch_22_Test M->T Retrieval (per 32 samples): R@1=0.779, R@2=0.897, R@3=0.935\n",
      "Epoch_22_Test T->M Retrieval (per 32 samples): R@1=0.768, R@2=0.903, R@3=0.941\n",
      "Model saved: clip_motion_align_epoch_CMP_22.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/300: 100%|██████████| 177/177 [00:19<00:00,  9.19it/s, loss=0.2971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/300] - Train Average Loss: 0.2940\n",
      "[Validate at epoch 23] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_23_Test: 100%|██████████| 32/32 [00:02<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_23_Test Average Contrastive Loss: 0.7289\n",
      "Epoch_23_Test M->T Retrieval (per 32 samples): R@1=0.759, R@2=0.899, R@3=0.937\n",
      "Epoch_23_Test T->M Retrieval (per 32 samples): R@1=0.753, R@2=0.898, R@3=0.938\n",
      "Model saved: clip_motion_align_epoch_CMP_23.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/300: 100%|██████████| 177/177 [00:18<00:00,  9.45it/s, loss=0.2312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/300] - Train Average Loss: 0.2813\n",
      "[Validate at epoch 24] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_24_Test: 100%|██████████| 32/32 [00:02<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_24_Test Average Contrastive Loss: 0.6954\n",
      "Epoch_24_Test M->T Retrieval (per 32 samples): R@1=0.777, R@2=0.891, R@3=0.939\n",
      "Epoch_24_Test T->M Retrieval (per 32 samples): R@1=0.780, R@2=0.899, R@3=0.945\n",
      "Model saved: clip_motion_align_epoch_CMP_24.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/300: 100%|██████████| 177/177 [00:18<00:00,  9.71it/s, loss=0.1204]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/300] - Train Average Loss: 0.2795\n",
      "[Validate at epoch 25] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_25_Test: 100%|██████████| 32/32 [00:02<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_25_Test Average Contrastive Loss: 0.6870\n",
      "Epoch_25_Test M->T Retrieval (per 32 samples): R@1=0.775, R@2=0.891, R@3=0.946\n",
      "Epoch_25_Test T->M Retrieval (per 32 samples): R@1=0.775, R@2=0.904, R@3=0.939\n",
      "Model saved: clip_motion_align_epoch_CMP_25.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/300: 100%|██████████| 177/177 [00:19<00:00,  9.06it/s, loss=0.3347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/300] - Train Average Loss: 0.2589\n",
      "[Validate at epoch 26] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_26_Test: 100%|██████████| 32/32 [00:02<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_26_Test Average Contrastive Loss: 0.7497\n",
      "Epoch_26_Test M->T Retrieval (per 32 samples): R@1=0.763, R@2=0.878, R@3=0.930\n",
      "Epoch_26_Test T->M Retrieval (per 32 samples): R@1=0.751, R@2=0.889, R@3=0.945\n",
      "Model saved: clip_motion_align_epoch_CMP_26.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/300: 100%|██████████| 177/177 [00:18<00:00,  9.36it/s, loss=0.2329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300] - Train Average Loss: 0.2525\n",
      "[Validate at epoch 27] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_27_Test: 100%|██████████| 32/32 [00:01<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_27_Test Average Contrastive Loss: 0.7312\n",
      "Epoch_27_Test M->T Retrieval (per 32 samples): R@1=0.754, R@2=0.885, R@3=0.943\n",
      "Epoch_27_Test T->M Retrieval (per 32 samples): R@1=0.764, R@2=0.884, R@3=0.944\n",
      "Model saved: clip_motion_align_epoch_CMP_27.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/300: 100%|██████████| 177/177 [00:18<00:00,  9.39it/s, loss=0.2670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/300] - Train Average Loss: 0.2463\n",
      "[Validate at epoch 28] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch_28_Test: 100%|██████████| 32/32 [00:01<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_28_Test Average Contrastive Loss: 0.7094\n",
      "Epoch_28_Test M->T Retrieval (per 32 samples): R@1=0.758, R@2=0.888, R@3=0.943\n",
      "Epoch_28_Test T->M Retrieval (per 32 samples): R@1=0.758, R@2=0.891, R@3=0.942\n",
      "Model saved: clip_motion_align_epoch_CMP_28.pt\n",
      "Early stopping triggered!\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.num_epochs):\n",
    "    \n",
    "    if epoch + 1 == opt.pretrain_epochs + 1:\n",
    "        \n",
    "        for param in clip_model.text_model.encoder.layers[-1].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in clip_model.text_model.final_layer_norm.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=opt.lr_finetune,\n",
    "            weight_decay=opt.weight_decay\n",
    "        )\n",
    "        print(\"Stage 2: Fine-tuning CLIP text encoder's last layer (and final_layer_norm) with lower lr.\")\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{opt.num_epochs}\")\n",
    "\n",
    "\n",
    "\n",
    "    for step, batch_data in enumerate(pbar):\n",
    "        caption, motion, m_length = batch_data\n",
    "\n",
    "        \n",
    "        caption = [c.lower() for c in caption]\n",
    "        text_enc = clip_tokenizer(\n",
    "            caption,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=opt.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = text_enc[\"input_ids\"].to(opt.device)\n",
    "        attention_mask = text_enc[\"attention_mask\"].to(opt.device)\n",
    "\n",
    "       \n",
    "        if isinstance(motion, list):\n",
    "            motion = torch.stack([torch.tensor(m, dtype=torch.float32) for m in motion], dim=0)\n",
    "        else:\n",
    "            motion = motion.float()\n",
    "        motion = motion.to(opt.device)\n",
    "        m_length = m_length.to(opt.device)\n",
    "\n",
    "        \n",
    "        motion_emb, text_emb = model(motion, m_length, input_ids, attention_mask)\n",
    "        loss = clip_contrastive_loss(motion_emb, text_emb, model.logit_scale)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_loss = total_loss / max(count, 1)\n",
    "    print(f\"Epoch [{epoch+1}/{opt.num_epochs}] - Train Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "   \n",
    "    print(f\"[Validate at epoch {epoch+1}] ...\")\n",
    "    test_loss = evaluate_model(model, test_loader, clip_tokenizer, opt, desc=f\"Epoch_{epoch+1}_Test\")\n",
    "    model_path = f\"clip_motion_align_epoch_CMP_{epoch+1}.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved: {model_path}\")\n",
    "\n",
    "   \n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        no_improve_count = 0\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "        if no_improve_count >= max_no_improve:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stablemofusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
